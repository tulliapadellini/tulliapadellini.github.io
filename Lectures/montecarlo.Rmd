---
title: "Basic Monte Carlo"
subtitle: "Statistical Methods for Data Science"
date: 2016-10-12
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
```

## The intuition:

Remember the (weak) Law of Large Numbers? Just a quick recap: if $X_1,\dots, X_n$ are i.i.d. random variables from a distribution $F$ with mean $\mu$ and variance $\sigma^2$, then the sample mean $\bar{X}_n$ converges in probability to the population mean $\mu$. 

Using more formulas, we can write the LLN as $$ \bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i  \rightarrow \mu =\int xdF(x)$$ as $n\rightarrow \infty$. One way to look at this is that, if the sample size $n$ is "close to infinity" (or more generally, if $n$ is "large enough"), then we have $$\frac{1}{n}\sum_{i=1}^n X_i \approx \int xdF. $$

This means that, if we are able to simulate an arbitrarily large amount of observations $X_i$ from $F$, then we can approximate arbitrarily well the mean $\mu$ of the distribution just by sample average. 

But this is not all! The best part is that by the LLS (Law of the Lazy Statistician) we also have that $$\frac{1}{n}\sum_{i=1}^n h(X_i) \approx \int h(x)dF .$$
In some sense, we are saying that **if we are able to sample from the distribution $F$, we can approximate arbitrarily complex integrals**. 

You may not see it straight away but this has **huge** consequences, such as: _you may not ever have to solve an integral analytically again_... Easy to see why LLN is an important result, right? 

Using simulations from known random variables to approximate integrals is the core concept of the so-called **Monte Carlo methods**. In general, Monte Carlo methods are numerical techniques which rely on random sampling to approximate their results.

Incidentally, Monte Carlo [has a pretty interesting history](http://www.nowozin.net/sebastian/blog/history-of-monte-carlo-methods-part-1.html), and dates back to von Neumann and the Manhattan Project (although some claims that the first Monte Carlo was used to solve the problem of [Buffon's needle](https://en.wikipedia.org/wiki/Buffon%27s_needle) almost $200$ years before).


## Standard Integrals 

Monte Carlo is first and foremost one way of approximating integrals that we cannot (or do not want to) solve analytically. Consider for example: $$ \int^{2.5} _1 \frac{\sec x + \tan x}{(\sec x -\tan x)(4\tan ^2 x)^2} 8 \sec ^2 x d x. $$

If we can write this integral as an Expected Value then we can solve it using Monte Carlo. In actual fact it is pretty easy to do it. 

Remember that the density $f_U(x)$ of a continuous uniform random variable $U\sim(a,b)$ is $$f_U (x) = \begin{cases} \frac{1}{b-a} & x\in[a,b]\\
0 & \text{otherwise}
\end{cases}$$


For $a =1$ and $b=2.5$ we have:
$$f_U (x) = \begin{cases} \frac{1}{1.5} & x\in[1,2.5]\\
0 & \text{otherwise}
\end{cases}$$

This is enough to write the previous integral as an expectation: 
$$ \int^{2.5} _1 \frac{\sec x + \tan x}{(\sec x -\tan x)(4\tan ^2 x)^2} 8 \sec ^2 x \cdot 1\cdot d x =$$
$$ = \int^{2.5} _1 \frac{\sec x + \tan x}{(\sec x -\tan x)(4\tan ^2 x)^2} 8 \sec ^2 x \cdot \frac{1.5}{1.5}d x = $$
$$ = \int^{2.5} _1 \frac{\sec x + \tan x}{(\sec x -\tan x)(4\tan ^2 x)^2} 8 \sec ^2 x \cdot 1.5 f_U(x)d x = $$
$$  = \int^{2.5} _1 \frac{\sec x + \tan x}{(\sec x -\tan x)(4\tan ^2 x)^2} 8 \sec ^2 x 1.5 d F_U(x) =$$
$$  = \int^{2.5} _1 h(x) d F_U(x) = \mathbb{E}_{F_U}[h(X)] $$

```{r}

h.funct = function(x){
  num   = 1/cos(x) + tan(x)
  denom = (1/cos(x) - tan(x))*(4*tan(x)^2)^2
  num/denom * 8 * 1/cos(x) * 1.5
}

```

```{r}
h.funct(runif(1,1,2.5))
```
This function returns one observation from the random variable $Y = h(X)$.

If we repeat the procedure $n$ times, we get a sample $Y_1, \dots, Y_n$ from the distribution of $Y$.
```{r}
n = 10000 
y.sample  = replicate(n, h.funct(runif(1, 1, 2.5)))
y.average = mean(y.sample)
y.average
```

## "Strange" Transformations of Random Variables

Suppose we are interested in the random variable $$Y = \min \left\{k \text{  such that  }\sum_{i=1}^k u_i<1, \quad u_i \sim U(0,1)\right\} $$ in other words the variable defined as the minimum number $k$ such that $\sum_{i=1} ^k u_i < 1$, where $u_1, \dots, u_k$ are i.i.d. random variables from a $Unif(0,1)$. This is nothing but a function of a uniform random variable, so we can write it as $h(X)$, where $X\sim Unif(0,1)$.

We are interested in the expected value of $Y$, and it is difficult to compute it analytically. However if we use simulations, things become a lot easier.

```{r}

h.funct = function(){
  s = 0
  k = 0
  while( s < 1){
    u = runif(1)
    s = s+u
    k = k+1
    }
  return(k)
}

```
The function returns one observation simulated from the random variable $Y$. If we replicate the procedure $n$ times, we get a sample $Y_1,\dots,Y_n$ distributed as $Y$. 
```{r}
n = 10000
y.sample  = replicate(n, h.funct() ) 
```

We can use the sample average of this new sample to estimate the population mean of the variable $Y$.
```{r}
y.average = mean(y.sample)
y.average
```
**Little side remark:** Does it remind you of anything? It turns out that $\mathbb{E}[Y]=e$, so this is just another way to define Euler's number. 

This is good already, but we can do more! We have an entire sample $Y_1,\dots,Y_n$ generated from the unknown distribution of $Y$, which we can use to carry on any kind of inference procedure (which is something useless at this point of the course but please keep it in mind, it will be extremely important later on!). As for now the only thing you can do is to analyse the distribution of $Y$ looking at the histogram:
```{r}
hist(y.sample, col=rgb(.6,0,.4,.3))
```

## Monte Carlo for the Coupon Problem

As our last example, let us consider an exercise of basic probability, such as those you had to solve before Test::01.

Remember Pokemon Go? Old stuff, time flies...


The idea behind the game is easy: 

1. walk around 
1. encounter a Pokemon at random 
1. catch it

and then iterate the procedure until you had all of the 145 available Pokemon. 

Different Pokemon have different probability of appearing, so you could meet the same common Pokemon many many times before meeting a new rare one. Typically you would end up with a lot of Pidgeys and no Snorlaxes, and it might take a while to complete your pokedex (i.e. catch all the Pokemon). Before starting this battery-draining adventure, you might want to know: how long will it take to catch one for each kind of Pokemon? How many Pokemon do I need to encounter in order to end the game? 

It turns out that this is a well known probability problem, so much so that it has its own name: **the Coupon problem**. 

Let us rewrite it a more rigorous way, and let us simplify the problem a little bit by assuming that all Pokemon appear with the same probability. 
Denote by $X_i$ the number of encounters it takes for the player to find the $i-th$ new Pokemon after the $(i-1)$-th Pokemon has been caught. Clearly $\mathbb{E}[X_1] =1$ because the player starts with no Pokemon. After the $(i-1)$-th Pokemon has been caught, there are $145 - (i-1)$ possible Pokemon that could be the new $i$-th Pokemon. We can interpret the process of waiting for the new $i$-th Pokemon as a geometric distribution, where each trial is meeting a Pokemon, the "success" is getting any of the $n-(i-1)$ unobserved Pokemon and "failure" is getting a duplicate of something we already have. 

We can thus assume that $X_i- 1 \sim Geom(p_i)$, and use properties of the distribution to find that $\mathbb{E}[X_i] =\frac{1}{p_i}$.

Remember, we are interested in the number of encounters we need to capture all Pokemon $Y$, which is the sum of the $X_i$. 
In theory you could solve this problem with the tools that you already have (+ pen and paper), in fact, by linearity of the expected value, the problem consists in computing a bunch of expected values for Geometric distributions, i.e. $$ \mathbb{E}[Y] = \mathbb{E}[X_1 +\dots +X_{145}] = \mathbb{E}[X_1] + \dots \mathbb{E}[X_{145}].$$

The "tricky" part here is how to compute the parameter $p_i$ of the Geometric distribution. If we assume that all the Pokemon have the same probability of appearing we have that, the probability of meeting the $i$-th new Pokemon, given that you already met $(i-1)$ distinct Pokemon is $$p_i=\frac{145-(i-1)}{145}.$$
In practice however, if we remove the oversimplifying assumption that all Pokemon have the same probability of appearing, computing this probability becomes rather long and tedious (although it is possible). Monte Carlo provides a fast (and almost brainless!) alternative. 
First thing first: load the data.
```{r}
library(readr)
spawn <- read_csv("spawn-by-typ.csv")
```

Then define the sample space and the probability of encountering a Pokemon:
```{r}
pokemon_sample_space = spawn$pokemon_id
spawn_prob = spawn$appeareances
```

Define a function that represent the encounter with a random Pokemon:
```{r}
find.pokemon = function(){
  sample(pokemon_sample_space, 1, replace=TRUE, prob = spawn_prob)
}

sum(spawn_prob)
```
**Warning**: `spawn_prob` is not a proper probability distribution, but it does not matter because `sample` standardizes it automatically.

We finally define a function that will give us the number of Pokemon that we need to meet before we have a number of distinct Pokemon equal to `num_distinct_poke`. This is our function $h$.
```{r}
simulate.catch.them.all <- function(num_distinct_poke){
  captured <- c()
  while(length(unique(captured)) < num_distinct_poke){
    captured <- c(captured, find.pokemon())
  }
  length(captured)
}
```
Exactly as in the previous case, this function returns a random draw from the distribution of $Y$; if we want to build the sample average we need, well, a sample, so we iterate the procedure.
```{r}
n = 1000
y.sample  = replicate(n,simulate.catch.them.all(10))
y.average = mean(y.sample)
y.average
```
This means that in order to get `r 10` different Pokemon we need to run into `r y.average` Pokemon.

