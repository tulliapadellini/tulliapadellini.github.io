<!DOCTYPE html>
<html lang="en-us">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Tullia Padellini">
    <meta name="description" content="PhD student in Statistics at Sapienza University of Rome">
    <meta name="keywords" content="[still very much under construction]">

    <base href="/">
    <title>
  The almighty Bootstrap · Tullia Padellini
</title>

    <link rel="canonical" href="/post_ita/2018-04-29-bootstrap/">

    <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
    <link rel="stylesheet" href="//cdn.rawgit.com/necolas/normalize.css/master/normalize.css">
    <link rel="stylesheet" href="/css/style.min.css">

    <link rel="icon" type="image/png" href="/images/coding-2.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/coding.png" sizes="16x16">

    

    <meta name="generator" content="Hugo 0.39" />
  </head>

  <body>
    <main class="wrapper">
      <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


<nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Tullia Padellini
    </a>
    
    <ul class="navigation-list float-right">
      
      <li class="navigation-item">
        <a class="navigation-link" href="/blog/">Blog</a>
      </li>
      
      <li class="navigation-item">
        <a class="navigation-link" href="/about/">About</a>
      </li>
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>The almighty Bootstrap</h1>
    </header>

    <div id="ingredienti-di-base" class="section level3">
<h3>Ingredienti di base</h3>
<p>Riprendiamo il classico setup visto ad inferenza, ossia supponiamo di avere un campione <span class="math inline">\(X_1,\dots X_n\)</span> di variabili indipendenti ed identicamente distribuite (<em>i.i.d.</em>) proveniente da una distribuzione <span class="math inline">\(F\)</span>, dove <span class="math inline">\(F(x) = \mathbb{P}(X_i\leq x)\)</span>.</p>
<p>Indichiamo con <span class="math inline">\(\mu_F\)</span> e <span class="math inline">\(\sigma^2 _F\)</span> rispettivamente la media e la varianza della generica variabile <span class="math inline">\(X_i\)</span>. La notazione con <span class="math inline">\(F\)</span> sottoscritto serve a ricordare che sia <span class="math inline">\(\mu_F\)</span> che <span class="math inline">\(\sigma^2_F\)</span> sono funzioni della funzione di ripartizione, infatti:</p>
<ul>
<li><span class="math inline">\(\mu_F = \mathbb{E}_F[X_i] = \int xdF(x)\)</span></li>
<li><span class="math inline">\(\sigma^2_F = \mathbb{V}_F[X_i] = \int (x-\mu)^2 dF(x)\)</span></li>
</ul>
<p>Consideriamo poi una statistica <span class="math inline">\(T_n =h(X_1,\dots,X_n)\)</span>.</p>
<hr />
<p><strong>Goal(s) di oggi:</strong> quantificare l’incertezza su <span class="math inline">\(T_n\)</span></p>
<ul>
<li>stimandone la varianza <span class="math inline">\(\mathbb{V}_F [T_n]\)</span></li>
<li>costruendo un intervallo di confidenza per <span class="math inline">\(T_n\)</span></li>
</ul>
<hr />
</div>
<div id="stima-della-varianza" class="section level2">
<h2>Stima della Varianza</h2>
<p><strong>Attenzione</strong>: la varianza di una statistica <span class="math inline">\(T_n\)</span> è sempre una funzione della funzione di ripartizione <span class="math inline">\(F\)</span>, che è incognita. Un esempio? Consideriamo la statistica più famosa di sempre, la media campionaria, ossia <span class="math inline">\(T_n =\bar{X}_n\)</span>. Sempre da inferenza ricordiamo che <span class="math display">\[\mathbb{V}[\bar{X}_n]=\frac{\mathbb{V}[X]}{n} = \frac{1}{n}\int (x-\mu)^2 dF(x).\]</span></p>
<p>In generale possiamo scrivere la quantità di interesse <span class="math inline">\(\mathbb{V}_F [T_n]\)</span> come un integrale, e la settimana scorsa avete visto che, usando metodi Monte Carlo, si possono approssimare integrali molto complicati simulando.</p>
<p>Nel nostro esempio il problema sarebbe ridotto a:</p>
<ol style="list-style-type: decimal">
<li>Generare un nuovo campione <span class="math inline">\(X_1^*,\dots,X_n^* \sim F\)</span></li>
<li>Calcolare <span class="math inline">\(T_n^* =h(X_1^*,\dots,X_n^*)\)</span></li>
<li>Ripetere il procedimento <span class="math inline">\(B\)</span> volte in modo da ottenere <span class="math inline">\(T_{n,1}^*,\dots, T_{n,B}^*\)</span> osservazioni</li>
<li>Approssimare <span class="math inline">\(\mathbb{V}_F [T_n]\)</span> con la varianza campionaria di <span class="math inline">\(T_{n,1}^*,\dots, T_{n,B}^*\)</span>; per la legge dei grandi numeri si ha che al crescere di <span class="math inline">\(B\)</span> <span class="math display">\[ vboot = \frac{1}{B}\sum_{i=1} ^B (T^*_{n,i} - \bar{T}^*)^2 \rightarrow \mathbb{V}_F [T_n]. \]</span></li>
</ol>
<p>Purtroppo <span class="math inline">\(F\)</span> è incognita e non possiamo usarla per generare nuove osservazioni, ma possiamo stimarla. L’idea alla base del bootstrap è semplice:</p>
<ol style="list-style-type: decimal">
<li>Stimare <span class="math inline">\(F\)</span> incognita con una <span class="math inline">\(\hat{F}\)</span> <em>nota</em> (e di conseguenza stimare <span class="math inline">\(\mathbb{V}_F [T_n]\)</span> con <span class="math inline">\(\mathbb{V}_{\hat{F}} [T_n]\)</span>).</li>
<li>Approssimare <span class="math inline">\(\mathbb{V}_{\hat{F}} [T_n]\)</span> simulando da <span class="math inline">\(\hat{F}\)</span>.</li>
</ol>
<p>Nel bootstrap ci sono dunque due tipi di errore:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\hat{F}\)</span> non è <span class="math inline">\(F\)</span> (e la differenza potrebbe non essere trascurabile)</li>
<li><span class="math inline">\(vboot \approx \mathbb{V}_{\hat{F}} [T_n]\)</span> (ma questo errore puè essere reso piccolo a piacere).</li>
</ol>
<div id="bootstrap-empirico-o-non-parametrico" class="section level3">
<h3>Bootstrap Empirico (o non-parametrico)</h3>
<p>Il modo più semplice di stimare la funzione di ripartizione <span class="math inline">\(F\)</span> è attraverso la funzione di ripartizione empirica <span class="math inline">\(\mathbb{F}_n\)</span>, definita come <span class="math display">\[\mathbb{F}_n(x) = \sum_{i=1}^n \mathbb{I}[X_i\leq x].\]</span></p>
<p>La distribuzione empirica mette massa di probabilità <span class="math inline">\(1/n\)</span> su ciascuna osservazione <span class="math inline">\(X_i\)</span> quindi simulare da <span class="math inline">\(\mathbb{F}_n\)</span> non vuol dire altro estrarre con ripetizione dal campione “originale” <span class="math inline">\(X_1,\dots, X_n\)</span>.</p>
<p><strong>ESEMPIO:</strong></p>
<p>Consideriamo <span class="math inline">\(X_1,\dots, X_n \sim N(0,1)\)</span>.</p>
<pre class="r"><code>Xn = rnorm(100)</code></pre>
<p>Per generare un campione <span class="math inline">\(X_1^*,\dots, X_n^* \sim \mathbb{F}_n\)</span> possiamo usare la funzione <code>sample</code>:</p>
<pre class="r"><code>Xstar = sample(Xn, size=100, replace=TRUE)</code></pre>
<p>Confrontiamo ora la distribuzione empirica con quella teorica:</p>
<pre class="r"><code>hist(Xn, col=rgb(1,0,0,.3), probability = T, main=&quot;&quot;)
hist(Xstar, add=TRUE, col=rgb(0,0,1,.3), probability = T)
curve(dnorm, col=&quot;red&quot;, lwd=3, add=TRUE)</code></pre>
<p><img src="/post_ita/2018-04-29-bootstrap_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>La ragione per cui scegliamo <span class="math inline">\(\mathbb{F}_n\)</span> come stima di <span class="math inline">\(F\)</span> è che al crescere della numerosità campionaria <span class="math inline">\(n\)</span>, le due distribuzioni sono equivalenti.</p>
<pre class="r"><code>Xn = rnorm(10000)
Xstar = sample(Xn, size=10000, replace=TRUE)

hist(Xn, col=rgb(1,0,0,.3), probability = T)
hist(Xstar, add=TRUE, col=rgb(0,0,1,.3), probability = T)
curve(dnorm, col=&quot;red&quot;, lwd=3, add=TRUE)</code></pre>
<p><img src="/post_ita/2018-04-29-bootstrap_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div id="esempio-bootstrap-per-la-mediana" class="section level4">
<h4>ESEMPIO: Bootstrap per la mediana</h4>
<p>Ora (finalmente!) vediamo come calcolare la stima bootstrap della varianza di una statistica, in particolare scegliamo <span class="math inline">\(T_n = \text{Mediana}(X_1,\dots, X_n)\)</span>.</p>
<pre class="r"><code>Xn = rexp(100)
Tn = median(Xn)

boot.median=function(X, B=10000){
  Tstar=c()
  for(i in 1:B ){
    Xstar = sample(Xn, size=length(Xn), replace=TRUE)
    Tstar[i] = median(Xstar)
  }
  return(Tstar)
}

boot.emp = boot.median(Xn)</code></pre>
<p>L’approssimazione di <span class="math inline">\(\mathbb{V}_{\hat{F}} [T_n]\)</span> è:</p>
<pre class="r"><code>var(boot.emp)</code></pre>
<pre><code>## [1] 0.005462682</code></pre>
<p>Il vettore <code>Tstar</code> contiene il campione <span class="math inline">\(T_{n,1}^*,\dots, T_{n,B}^*\)</span>, possiamo analizzarne la distribuzione campionaria:</p>
<pre class="r"><code>hist(boot.emp, col=rgb(.0,.6,.3,.3), probability = T)</code></pre>
<p><img src="/post_ita/2018-04-29-bootstrap_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
</div>
<div id="bootstrap-parametrico" class="section level3">
<h3>Bootstrap Parametrico</h3>
<p>Utilizzare la distribuzione empirica non è l’unico modo di stimare <span class="math inline">\(F\)</span>. Ad esempio se <span class="math inline">\(F\)</span> è una distribuzione parametrica, <span class="math inline">\(F=F_{\theta}\)</span>, possiamo usare il campione <span class="math inline">\(X_1,\dots,X_n\)</span> per ottenere una stima <span class="math inline">\(\hat{\theta}\)</span> per il parametro <span class="math inline">\(\theta\)</span> e considerare lo stimatore plug-in <span class="math inline">\(\hat{F}=F_{\hat{\theta}}\)</span>.</p>
<p>Consideriamo lo stesso esempio di prima, i.e. un campione di <span class="math inline">\(n=100\)</span> osservazioni generate da una v.a. esponenziale di parametro <span class="math inline">\(\lambda=1\)</span>. Supponiamo di non conoscere il parametro e di doverlo stimare, ad esempio con il metodo della massima verosimiglianza:</p>
<pre class="r"><code>LL = function(lambda) {
    R = dexp(Xn, lambda)
    -sum(log(R))
}

lambda = optim(par=1, LL)$par</code></pre>
<pre><code>## Warning in optim(par = 1, LL): one-dimensional optimization by Nelder-Mead is unreliable:
## use &quot;Brent&quot; or optimize() directly</code></pre>
<pre class="r"><code>param.boot.median=function(X, thetahat, B=10000){
  Tstar=c()
  for(i in 1:B ){
    Xstar = rexp(length(X), rate=thetahat)
    Tstar[i] = median(Xstar)
  }
  return(Tstar)
}

boot.param = param.boot.median(Xn, thetahat = lambda)</code></pre>
<p>L’approssimazione di <span class="math inline">\(\mathbb{V}_{\hat{F}} [T_n]\)</span> è:</p>
<pre class="r"><code>var(boot.param)</code></pre>
<pre><code>## [1] 0.008916187</code></pre>
<p>Il vettore <code>Tstar</code> contiene il campione <span class="math inline">\(T_{n,1}^*,\dots, T_{n,B}^*\)</span>, possiamo analizzarne la distribuzione campionaria:</p>
<pre class="r"><code>hist(boot.emp, col=rgb(0,.6,0.3,.3), probability = T, main = &quot;&quot;)
hist(boot.param, col=rgb(0,.1,.6,.3), probability = T, add=TRUE)</code></pre>
<p><img src="/post_ita/2018-04-29-bootstrap_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<div id="bootstrap-empirico-vs-parametrico" class="section level5">
<h5>Bootstrap Empirico vs Parametrico</h5>
<ul>
<li>Se il modello è specificato correttemente, il bootstrap parametrico è preferibile perchè <span class="math inline">\(F_{\hat{\theta}}\)</span> converge ad <span class="math inline">\(F\)</span> più velocemente di <span class="math inline">\(\mathbb{F}_n\)</span>.</li>
<li>Se l’assunzione distribuzionale è sbagliata però, <span class="math inline">\(F_{\hat{\theta}}\)</span> non converge ad <span class="math inline">\(F\)</span>.</li>
</ul>
</div>
</div>
</div>
<div id="intervalli-di-confidenza" class="section level2">
<h2>Intervalli di Confidenza</h2>
<p>Esistono diversi modi per costruire intervalli di confidenza utilizzando procedure bootstrap.</p>
<div id="approssimazione-normale" class="section level4">
<h4>1. Approssimazione Normale</h4>
<p>Se la statistica <span class="math inline">\(T_n\)</span> ha distribuzione approssimativamente normale, possiamo utilizzare <span class="math display">\[T_n \pm z_{1-\alpha/2} \sqrt{vboot} \]</span></p>
<p>Consideriamo l’esempio dell’esponenziale. In questo caso la distribuzione campionaria della statistica <span class="math inline">\(T_n =\text(Mediana)(X_1,\dots,X_n)\)</span> può essere considerata normale:</p>
<pre class="r"><code>hist(boot.param, col=rgb(.1,.0,.6,.3), prob=TRUE)</code></pre>
<p><img src="/post_ita/2018-04-29-bootstrap_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code>qqnorm(boot.param, pch=20, col=rgb(.8,0,.4,.4))
qqline(boot.param)</code></pre>
<p><img src="/post_ita/2018-04-29-bootstrap_files/figure-html/unnamed-chunk-12-2.png" width="672" /></p>
<p>L’intervallo di confidenza per <span class="math inline">\(T_n\)</span> è quindi:</p>
<pre class="r"><code>L.int = Tn - 1.96 * sd(boot.param)
U.int = Tn + 1.96 * sd(boot.param)
N.int = c(L.int, U.int)
N.int</code></pre>
<pre><code>## [1] 0.4505019 0.8206501</code></pre>
</div>
<div id="percentili" class="section level4">
<h4>2. Percentili</h4>
<p>Abbiamo detto che <span class="math inline">\(T_{n,1}^*,\dots, T_{n,B}^*\)</span> è un campione, largo a piacere, dalla distribuzione campionaria di <span class="math inline">\(T_n\)</span>. Fino ad ora ci siamo limitati ad usarlo per stimare la varianza ma possiamo farci molto di più! Ad esempio possiamo usare questo campione per stimare i quantili della distribuzione di <span class="math inline">\(T_n\)</span>. Un modo immediato per costruire un intervallo di confidenza è dunque usando i quantili empirici di livello <span class="math inline">\(\alpha/2\)</span> e <span class="math inline">\((1-\alpha/2)\)</span>, <span class="math inline">\(T^*_{n,\alpha/2}, T^*_{n,1-\alpha/2}\)</span> come estremi.</p>
<pre class="r"><code>Perc.int = quantile(boot.param, c(0.025, 0.975))
Perc.int</code></pre>
<pre><code>##      2.5%     97.5% 
## 0.4887328 0.8613137</code></pre>
</div>
<div id="quantita-pivotali" class="section level4">
<h4>3. Quantità pivotali</h4>
<p>Il metodo dei percentili è immediato ma potrebbe non essere molto accurato, un’alternativa lievemente più precisa è il metodo del pivot, che considera la quantità pivotale <span class="math inline">\(T^*_n - T_n\)</span>. L’intervallo che si ottiene con questo metodo è il seguente: <span class="math display">\[[2T_n - T^*_{n,1-\alpha/2}, 2T_n -T^*_{n,\alpha/2}] \]</span></p>
<pre class="r"><code>Pivot.int = c(2*Tn - quantile(boot.param, c(0.975, 0.025))) 
Pivot.int</code></pre>
<pre><code>##     97.5%      2.5% 
## 0.4098382 0.7824191</code></pre>
<p><strong>EXTRA - “Studentizzazione”:</strong> Il metodo delle quantità pivotali standard si basa sull’assunzione che <span class="math inline">\(T_n - T\)</span> e <span class="math inline">\(T^*_n - T_n\)</span> abbiano approssimativamente la stessa distribuzione. Quando questo non è vero, si può ricorrere alla studentizzazione, ossia considerare: <span class="math display">\[\tau = \frac{T_n - T}{\sqrt{\mathbb{V}[T_n]}} \]</span> <span class="math display">\[\tau^* = \frac{T^*_n - T_n}{\sqrt{\mathbb{V}[T^*_n]}} \]</span></p>
<p>Il vantaggio delle quantità “studentizzate” <span class="math inline">\(\tau\)</span> e <span class="math inline">\(\tau^*\)</span> è che hanno approssimativamente la stessa distribuzione anche quando <span class="math inline">\(T_n - T\)</span> e <span class="math inline">\(T^*_n - T_n\)</span> hanno distribuzioni diverse. Lo svantaggio di questo metodo è che richiedono un secondo giro di bootstrap per stimare la quantitè <span class="math inline">\(\sqrt{\mathbb{V}[T^*_n]}\)</span></p>
</div>
</div>
<div id="errori-subsampling" class="section level2">
<h2>Errori &amp; Subsampling</h2>
<p>Riprendiamo “Old Faithful”, i dati che avete visto nell’homework 1(?) relativi alla durata e ai tempi di attesa delle eruzioni di un vulcano.</p>
<pre class="r"><code>data(&quot;faithful&quot;)</code></pre>
<p>Supponiamo di essere interessati a studiare la durata massima di un’eruzione, ossia <span class="math inline">\(T_n=X_{(n)}=\max\{X_1,\dots,X_n\}\)</span>:</p>
<pre class="r"><code>Xn = faithful$eruptions
Tn = max(Xn)
Tn</code></pre>
<pre><code>## [1] 5.1</code></pre>
<pre class="r"><code>boot.max=function(X, B=10000){
  Tstar=c()
  for(i in 1:B ){
    Xstar = sample(X, size=length(X), replace=TRUE)
    Tstar[i] = max(Xstar)
  }
  
  int.boot = 2*max(X) - quantile(Tstar, c(0.975, 0.025))
  
  return(list(Tstar=Tstar, int.boot=int.boot))
}

boot.faith = boot.max(Xn)</code></pre>
<p>La distribuzione campionaria di <span class="math inline">\(X_n\)</span> stimata con il bootstrap è un po’ “strana”.</p>
<pre class="r"><code>hist(boot.faith$Tstar, probability = TRUE, col=rgb(.9,0,0,.3), main=&quot;&quot;)</code></pre>
<p><img src="/post_ita/2018-04-29-bootstrap_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Cerchiamo di capire se è un caso isolato o se c’è un problema di fondo. Siano <span class="math inline">\(X_1,\dots,X_n\sim U(0, \theta)\)</span>, e sia <span class="math inline">\(\hat{\theta}=X_{(n)}=max\{X_1,\dots,X_n\}\)</span>. Poniamo <span class="math inline">\(\theta=1\)</span> e generiamo un campione di <span class="math inline">\(n=50\)</span> osservazioni:</p>
<pre class="r"><code>Xn = runif(50)
Tn = max(Xn)
Tn</code></pre>
<pre><code>## [1] 0.995068</code></pre>
<pre class="r"><code>boot.prova = boot.max(Xn)</code></pre>
<p>Ricordiamo che nel caso di <span class="math inline">\(X_1,\dots,X_n\sim U(0, \theta)\)</span> la distribuzione di <span class="math inline">\(X_{(n)}\)</span> è <span class="math display">\[\mathbb{P}(X_{(n)}&lt;x)= \left(\frac{x}{\theta}\right)^n.\]</span> Confrontiamo la distribuzione stimata dal bootstrap con quella teorica (in blu).</p>
<pre class="r"><code>hist(boot.prova$Tstar, breaks=seq(0,1.3,by=0.05), prob= T, main=&quot;&quot;, col=rgb(.3,0.3,.7,.3))
curve(x^50, add=T, col=&quot;darkblue&quot;, lwd=4)</code></pre>
<p><img src="/post_ita/2018-04-29-bootstrap_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Le due distribuzioni sembrano comportarsi in modo diverso. Vediamo quali sono gli effetti di questa differenza sulla stima intervallare: Costruiamo 1000 intervalli bootstrap e vediamo la proporzione di questi in cui è contenuto il vero valore del parametro <span class="math inline">\(\theta=1\)</span>:</p>
<pre class="r"><code>boot.cis = replicate(1000, boot.max(X = runif(50), B = 1000)$int.boot)
true.coverage = mean((1 &gt;= boot.cis[1, ]) &amp; (1 &lt;= boot.cis[2, ]))
true.coverage</code></pre>
<pre><code>## [1] 0.86</code></pre>
<p>La copertura degli intervalli è decisamente inferiore a <span class="math inline">\(0.95\)</span>! In generale il bootstrap si comporta “male” nelle stime degli estremi.</p>
<p>Una possibile soluzione a questo problema è utilizzare un altro metodo di ricampionamento, il <em>subsampling</em>. In sostanza il subsampling è molto simile al bootstrap empirico, solo che al posto di ricampionare con ripetizione <span class="math inline">\(n\)</span> elementi dai dati osservati, il campione di subsampling viene creato estraendo senza ripetizione <span class="math inline">\(m\)</span> unitè dal campione originale (<span class="math inline">\(m\)</span> deve essere piccolo).</p>
<pre class="r"><code>sub.max=function(X, B=10000, m){
  Tstar=c()
  for(i in 1:B ){
    Xstar = sample(X, size=m, replace=FALSE)
    Tstar[i] = max(Xstar)
  }
  
  int.boot = 2*max(X) - quantile(Tstar, c(0.975, 0.025))
  return(list(Tstar=Tstar, int.sub=int.boot))
}


Xn = runif(50)
Tn = max(Xn)
Tn</code></pre>
<pre><code>## [1] 0.9926264</code></pre>
<pre class="r"><code>sub.prova = sub.max(Xn, m=20)</code></pre>
<p>Analizziamo ora la copertura degli intervalli creati con il subsampling:</p>
<pre class="r"><code>sub.cis = replicate(1000, sub.max(X = runif(50), B = 1000, m=25)$int.sub)
true.coverage = mean((1 &gt;= sub.cis[1, ]) &amp; (1 &lt;= sub.cis[2, ]))
true.coverage</code></pre>
<pre><code>## [1] 0.936</code></pre>
</div>

  </article>
</section>


      </div>

      <script src="//yihui.name/js/math-code.js"></script>
<script async
src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<footer class="footer">
  <section class="container">

  <font size=1> © 2018 - Powered by <a href="https://gohugo.io/">Hugo</a> with much help from <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.</font>
    
  
    
  </section>
</footer>

    </main>

    

  </body>

</html>
